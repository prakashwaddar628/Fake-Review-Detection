{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.18.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: C:\\Users\\praka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\n",
      "Requires: tensorflow-intel\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text, X_test_text, y_train, y_test, vectorizer = pd.read_pickle(\"../datasets/processed_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 89.70%\n",
      "Logistic Regression Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90      4071\n",
      "           1       0.90      0.89      0.90      4016\n",
      "\n",
      "    accuracy                           0.90      8087\n",
      "   macro avg       0.90      0.90      0.90      8087\n",
      "weighted avg       0.90      0.90      0.90      8087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_model = LogisticRegression(max_iter=500)\n",
    "log_model.fit(X_train_text, y_train)\n",
    "log_y_pred = log_model.predict(X_test_text)\n",
    "log_accuracy = accuracy_score(y_test, log_y_pred)\n",
    "print(f\"Logistic Regression Accuracy: {log_accuracy * 100:.2f}%\")\n",
    "print(\"Logistic Regression Report:\\n\", classification_report(y_test, log_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 88.35%\n",
      "Random Forest Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88      4071\n",
      "           1       0.88      0.89      0.88      4016\n",
      "\n",
      "    accuracy                           0.88      8087\n",
      "   macro avg       0.88      0.88      0.88      8087\n",
      "weighted avg       0.88      0.88      0.88      8087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_text, y_train)\n",
    "rf_y_pred = rf_model.predict(X_test_text)\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy * 100:.2f}%\")\n",
    "print(\"Random Forest Report:\\n\", classification_report(y_test, rf_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes Accuracy: 86.97%\n",
      "Naïve Bayes Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.87      4071\n",
      "           1       0.85      0.90      0.87      4016\n",
      "\n",
      "    accuracy                           0.87      8087\n",
      "   macro avg       0.87      0.87      0.87      8087\n",
      "weighted avg       0.87      0.87      0.87      8087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_text, y_train)\n",
    "nb_y_pred = nb_model.predict(X_test_text)\n",
    "nb_accuracy = accuracy_score(y_test, nb_y_pred)\n",
    "print(f\"Naïve Bayes Accuracy: {nb_accuracy * 100:.2f}%\")\n",
    "print(\"Naïve Bayes Report:\\n\", classification_report(y_test, nb_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_WORDS = 5000\n",
    "MAX_SEQUENCE_LENGTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import issparse\n",
    "\n",
    "if issparse(X_train_text):\n",
    "    X_train_text = X_train_text.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sparse matrix to text\n",
    "X_train_text = vectorizer.inverse_transform(X_train_text)\n",
    "X_train_text = [\" \".join(words) for words in X_train_text]  # Convert list of word arrays into sentences\n",
    "\n",
    "X_test_text = vectorizer.inverse_transform(X_test_text)\n",
    "X_test_text = [\" \".join(words) for words in X_test_text]  # Same for test data\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(X_train_text)  \n",
    "\n",
    "# Convert text to sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train_text)  \n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test_text)  \n",
    "\n",
    "# Pad sequences\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_SEQUENCE_LENGTH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = Sequential([\n",
    "    Embedding(MAX_NUM_WORDS, 128, input_length=MAX_SEQUENCE_LENGTH),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    LSTM(32),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1011/1011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 122ms/step - accuracy: 0.8078 - loss: 0.3881 - val_accuracy: 0.8885 - val_loss: 0.2639\n",
      "Epoch 2/5\n",
      "\u001b[1m1011/1011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 140ms/step - accuracy: 0.9225 - loss: 0.1909 - val_accuracy: 0.8924 - val_loss: 0.2567\n",
      "Epoch 3/5\n",
      "\u001b[1m 537/1011\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 140ms/step - accuracy: 0.9393 - loss: 0.1495"
     ]
    }
   ],
   "source": [
    "lstm_model.fit(X_train_pad, np.array(y_train), epochs=5, batch_size=32, validation_data=(X_test_pad, np.array(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_loss, lstm_accuracy = lstm_model.evaluate(X_test_pad, np.array(y_test))\n",
    "print(f\"LSTM Model Accuracy: {lstm_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Vocabulary Size: {len(tokenizer.word_index)}\")\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=X_train_pad.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pad = vectorizer.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.score(X_test_pad, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test_pad)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_test_text_reset = pd.Series(X_test_text).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in misclassified_idx[:5]:  \n",
    "    print(f\"Actual: {y_test_reset[idx]}, Predicted: {y_pred[idx]}\")  \n",
    "    print(f\"Review: {X_test_text[idx]}\")  # No need for .reset_index()\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training hybrid model from weak model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = max(\n",
    "    [(log_model, log_accuracy), (rf_model, rf_accuracy), (nb_model, nb_accuracy)], key=lambda x: x[1]\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lstm_accuracy > max(log_accuracy, rf_accuracy, nb_accuracy):\n",
    "    lstm_model.save(\"../models/lstm_model.h5\")\n",
    "    best_model = \"LSTM Model\"\n",
    "else:\n",
    "    with open(\"../models/model.pkl\", \"wb\") as model_file:\n",
    "        pickle.dump(best_model, model_file)\n",
    "    with open(\"../models/vectorizer.pkl\", \"wb\") as vectorizer_file:\n",
    "        pickle.dump(vectorizer, vectorizer_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best model selected: {best_model}\")\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
